---
category: news
title: "Shrinking massive neural networks used to model language"
excerpt: "Deep learning neural networks can be massive, demanding major computing power. In a test of the “lottery ticket hypothesis,” MIT researchers have found leaner, more efficient subnetworks hidden within BERT models."
publishedDateTime: 2020-12-01T05:28:00Z
originalUrl: "https://news.mit.edu/2020/neural-model-language-1201"
webUrl: "https://news.mit.edu/2020/neural-model-language-1201"
type: article
quality: 71
heat: 71
published: true

provider:
  name: Massachusetts Institute of Technology
  domain: mit.edu
  images:
    - url: "https://smartableai.github.io/artificial-intelligence/assets/images/organizations/mit.edu-50x50.jpg"
      width: 50
      height: 50

topics:
  - Machine Learning
  - AI
  - Natural Language Processing

images:
  - url: "https://news.mit.edu/sites/default/files/images/202011/MIT-BERT-Lottery-01-Press.jpg"
    width: 1500
    height: 1000
    isCached: true

secured: "Dl4Cmns2qPDFjodgwSoq9lU2r8SkZXD2lx4J83/Zmjr1X4590lArMQfRLIpyaJ1NQzNNgDR7boIzJPP+iIVHmoQNIbFDaJpcxMa03K7zzOwTA/1g72cNlzojVpf0mbVq8G7A6BINKNKhFm5kIcn3dUAdbJap3LOx+sXYKoRaVoNHefrXN6M+7LovKAGnqJG7mR/LM+5ddLYPt6osP3Z+FpNEj4iU2R19f/LnDGC3YqhkVVkSkvgA/Au4BgeG9CTfm1m1dPui/VDuGvMBpGbkWSluXryVIXDvKeAFfX2eb9PXib6Pa9blZpesARUf/F5CGRh3fpaYUUw3psQssUC73BnNc8r+/91dTo8wUh7HLCgLGD8Jdsvp9wvMhuWrydjtaw7h6OTG9Fq1D5rFGmFNX+e6kMV1f9mCHLu/LOnpNdhC93YJmp+ExxYJ7Ch4S98uK66W43DW3830y9iYbmZEb3lY/U0yzEHciw55t77yK5NgK1s8aCvieD9Z90y2PCH9IGziffa3L4EtxZfg0tQ3cA==;RGxMRmNn4nEAJE87bklIgA=="
---

