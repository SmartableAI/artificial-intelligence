---
category: news
title: "Shrinking massive neural networks used to model language"
excerpt: "Deep learning neural networks can be massive, demanding major computing power. In a test of the 'lottery ticket hypothesis,' researchers have found leaner, more efficient subnetworks hidden within BERT models."
publishedDateTime: 2020-12-01T23:47:00Z
originalUrl: "https://www.sciencedaily.com/releases/2020/12/201201144041.htm"
webUrl: "https://www.sciencedaily.com/releases/2020/12/201201144041.htm"
type: article
quality: 51
heat: -1
published: false

provider:
  name: Science Daily
  domain: sciencedaily.com
  images:
    - url: "https://smartableai.github.io/artificial-intelligence/assets/images/organizations/sciencedaily.com-50x50.jpg"
      width: 50
      height: 50

topics:
  - Natural Language Processing
  - AI
  - Machine Learning

related:
  - title: "Shrinking massive neural networks used to model language"
    excerpt: "Deep learning neural networks can be massive, demanding major computing power. In a test of the “lottery ticket hypothesis,” MIT researchers have found leaner, more efficient subnetworks hidden within BERT models."
    publishedDateTime: 2020-12-01T05:28:00Z
    webUrl: "https://news.mit.edu/2020/neural-model-language-1201"
    type: article
    provider:
      name: Massachusetts Institute of Technology
      domain: mit.edu
    quality: 71
    images:
      - url: "https://news.mit.edu/sites/default/files/images/202011/MIT-BERT-Lottery-01-Press.jpg"
        width: 1500
        height: 1000
        isCached: true

secured: "jUOEwKUQiAuuhYLpVp9/SmQHuWZAbllEC6GO7sZKpDvbxt4XTHU+1hQVWU590QVsIZ4MHGdGJcnFchhceRdfQKbOR8A36+9fBQV8B8yWINox0LKPR/pUJy5gRHwcvow8nxnWYLfzHy43XJFAH8Ihi0ernd7BHgjCYKCQ2p7Edv64gu6rTsbr8pPJ/48v3A3hbDVV1R76uDFypkXu5tv6HGAzEfAsxjVHIEHmVUbBe66gVazaUQ/tehboG3OLpWB2U4ISFKmN4DcYUaCM6kVhFPp11Lc9oenzrjQ0kdDOWRL0u1jHjvRRQ1tRi7jpQbDd792gp3KY7NvT1WeVeFLuhDHD2vruLmF/VSnziAXI6cM=;Xp00uW3nUvTIFt4JsYIhyQ=="
---

