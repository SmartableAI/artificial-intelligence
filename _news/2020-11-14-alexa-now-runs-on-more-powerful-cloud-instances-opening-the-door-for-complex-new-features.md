---
category: news
title: "Alexa now runs on more powerful cloud instances, opening the door for complex new features"
excerpt: "In addition to the Alexa team, Amazon Rekognition is also adopting the new chip as running models such as object classification on Inf1 instances resulted in eight times lower latency and doubled ..."
publishedDateTime: 2020-11-13T23:04:00Z
originalUrl: "https://www.techradar.com/news/alexa-now-runs-on-more-powerful-cloud-instances-opening-the-door-for-complex-new-features"
webUrl: "https://www.techradar.com/news/alexa-now-runs-on-more-powerful-cloud-instances-opening-the-door-for-complex-new-features"
ampWebUrl: "https://www.techradar.com/amp/news/alexa-now-runs-on-more-powerful-cloud-instances-opening-the-door-for-complex-new-features"
cdnAmpWebUrl: "https://www-techradar-com.cdn.ampproject.org/c/s/www.techradar.com/amp/news/alexa-now-runs-on-more-powerful-cloud-instances-opening-the-door-for-complex-new-features"
type: article
quality: 64
heat: -1
published: false

provider:
  name: TechRadar
  domain: techradar.com
  images:
    - url: "https://smartableai.github.io/artificial-intelligence/assets/images/organizations/techradar.com-50x50.jpg"
      width: 50
      height: 50

topics:
  - AWS AI
  - AI

images:
  - url: "https://cdn.mos.cms.futurecdn.net/cm2hxBobQuAFb4Bj3YRJQU-1200-80.jpg"
    width: 970
    height: 546
    isCached: true

related:
  - title: "Amazon begins shifting Alexaâ€™s cloud AI to its own silicon"
    excerpt: "On Thursday, an Amazon AWS blog post announced that the company has moved most of the cloud processing for its Alexa personal assistant off of Nvidia GPUs and onto its own Inferentia Application Specific Integrated Circuit (ASIC)."
    publishedDateTime: 2020-11-13T18:07:00Z
    webUrl: "https://arstechnica.com/gadgets/2020/11/amazon-begins-shifting-alexas-cloud-ai-to-its-own-silicon/"
    type: article
    provider:
      name: Ars Technica
      domain: arstechnica.com
    quality: 71
    images:
      - url: "https://cdn.arstechnica.net/wp-content/uploads/2020/11/InferentiaSmall-640x380.jpg"
        width: 640
        height: 380
        isCached: true
  - title: "Amazon Making In Roads Into Chip Industry; Now Uses Its Own Machine Learning Chips For Alexa Services"
    excerpt: "Each AWS Inferentia chip contains four NeuronCores that are equipped with a large on-chip cache. This cuts down on external memory accesses."
    publishedDateTime: 2020-11-17T10:35:00Z
    webUrl: "https://analyticsindiamag.com/aws-inferentia-alexa-machine-learning-chips-amazon/"
    type: article
    provider:
      name: Analytics India Magazine
      domain: analyticsindiamag.com
    quality: 41
    images:
      - url: "https://analyticsindiamag.com/wp-content/uploads/2020/11/andres-urena-tsBropDpnwE-unsplash-compressed-scaled.jpg"
        width: 2560
        height: 1707
        isCached: true

secured: "enO7t7+dizuVPbNDn6WpcYBSspt2Hs8OkEUjcNt71K0bmiunYf8FdmNVXcPNUjn7y6W4QwB17DjTZLT1r/b1wO9kEhNy1/ywAzXncTsDyavJShV6HSrbRCuzUfj+ZcmLuXU8CixgbpysBqXNfIXFc3PROroHo+Z5lBIfpUvO44j3fWybFkdOffsKss1/lOl7QrNBrw0x00Bl1WQIIutojFOJhihc1O7ggkAS5WNza/1X2hl//x8viVHK/5qKbMbmS5y88A39nMhbY6H9NXwKVF7O48ZpQX5NNc1VRLVf+m5bTw+WbalkE/EDU/73UyWOZTK0ww9P5ji9f/rImWDg+82ShG8zCFQ6FbRAcAJowEQ=;myQVTyDVAae+rlGLpqtzsQ=="
---

